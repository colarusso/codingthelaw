{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Three Notebook Example\n",
    "\n",
    "For your final notebook, feel free to duplicate this notebook and edit as needed. \n",
    "\n",
    "\n",
    "## Load Some Stuff\n",
    "\n",
    "This is where we load libraires and the like so we can do what we need. If you get an error saying a module is not loaded, open a new terminal/cmd line and try running: `pip install [module name]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    inputFunc = raw_input\n",
    "except NameError:\n",
    "    inputFunc = input\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import numpy as np\n",
    " \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "\n",
    "def evaluate(pred, labels_test):\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "    print (\"Accuracey: %s\"%acc)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test, pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fp)\n",
    "    percision = tp / (tp + fn)\n",
    "    f1 = (2 / ((1/recall)+(1/percision)))\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"True Negatives: %s\"%tn)\n",
    "    print (\"False Positives: %s\"%fp)\n",
    "    print (\"False Negatives: %s\"%fn)\n",
    "    print (\"True Positives: %s\"%tp)\n",
    "    print (\"Recall: %s\"%recall)\n",
    "    print (\"Precision: %s\"%percision)\n",
    "    print (\"F1 Score: %s\"%f1)\n",
    "\n",
    "def plot_bound(Z_val,data,col1,col2,binary):\n",
    "    # Z-val equals \"Yes\" value. E.g., \"Y\" or \"1\". \n",
    "    # data equals df\n",
    "    # col1 and col2 defines which colums to use from data\n",
    "    # Plot binary decision boundary. \n",
    "    # For this, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    x_min = float(data.iloc[:,[col1]].min())-float(data.iloc[:,[col1]].min())*0.10 \n",
    "    x_max = float(data.iloc[:,[col1]].max()+float(data.iloc[:,[col1]].min())*0.10)\n",
    "    y_min = 0.0; \n",
    "    y_max = float(training.iloc[:,[col2]].max())+float(training.iloc[:,[col2]].max())*0.10\n",
    "    h_x = (x_max-x_min)/100  # step size in the mesh\n",
    "    h_y = (y_max-y_min)/100  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "    if binary == 1:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])   \n",
    "        Z = np.where(Z==\"Y\",1,0)\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.pcolormesh(xx, yy, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here we load the data we collected and get it all ready to feed to our statistical model(s). That is, we are trying to make a table with one **target** column and one or more **features**. Here I'm loading happiness.csv from: https://data.somervillema.gov/Happiness/Somerville-Happiness-Survey-responses-2011-2013-20/w898-3dfm Note: you can find information on the data elements at this link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charmainewood/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (12,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>GISID</th>\n",
       "      <th>BldgNum</th>\n",
       "      <th>Address</th>\n",
       "      <th>Unit</th>\n",
       "      <th>StateClassCode</th>\n",
       "      <th>PropertyClass</th>\n",
       "      <th>Zoning</th>\n",
       "      <th>Map/Lot</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>...</th>\n",
       "      <th>Systems_Plumbing</th>\n",
       "      <th>Condition_YearBuilt</th>\n",
       "      <th>Condition_InteriorCondition</th>\n",
       "      <th>Condition_OverallCondition</th>\n",
       "      <th>Condition_OverallGrade</th>\n",
       "      <th>Parking_Open</th>\n",
       "      <th>Parking_Covered</th>\n",
       "      <th>Parking_Garage</th>\n",
       "      <th>UnfinishedBasementGross</th>\n",
       "      <th>FinishedBasementGross</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1063</td>\n",
       "      <td>23-67</td>\n",
       "      <td>2</td>\n",
       "      <td>117 119 Otis St\\nCambridge, MA\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>CONDO-BLDG</td>\n",
       "      <td>C-1</td>\n",
       "      <td>23-67</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3397</td>\n",
       "      <td>77-81</td>\n",
       "      <td>1</td>\n",
       "      <td>100A 102 Hampshire St\\nCambridge, MA\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>CONDO-BLDG</td>\n",
       "      <td>C-1</td>\n",
       "      <td>77-81</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5439</td>\n",
       "      <td>97-91</td>\n",
       "      <td>1</td>\n",
       "      <td>531 Putnam Ave\\nCambridge, MA\\n(42.357686, -71...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>CONDO-BLDG</td>\n",
       "      <td>C</td>\n",
       "      <td>97-91</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063</td>\n",
       "      <td>23-67</td>\n",
       "      <td>1</td>\n",
       "      <td>117 119 Otis St\\nCambridge, MA\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>CONDO-BLDG</td>\n",
       "      <td>C-1</td>\n",
       "      <td>23-67</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>23-29</td>\n",
       "      <td>1</td>\n",
       "      <td>94 5-96 Gore St\\nCambridge, MA\\n</td>\n",
       "      <td>2A</td>\n",
       "      <td>102</td>\n",
       "      <td>CONDOMINIUM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23-29-2A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>Average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PID  GISID  BldgNum                                            Address  \\\n",
       "0  1063  23-67        2                   117 119 Otis St\\nCambridge, MA\\n   \n",
       "1  3397  77-81        1             100A 102 Hampshire St\\nCambridge, MA\\n   \n",
       "2  5439  97-91        1  531 Putnam Ave\\nCambridge, MA\\n(42.357686, -71...   \n",
       "3  1063  23-67        1                   117 119 Otis St\\nCambridge, MA\\n   \n",
       "4  1035  23-29        1                   94 5-96 Gore St\\nCambridge, MA\\n   \n",
       "\n",
       "  Unit  StateClassCode PropertyClass Zoning   Map/Lot  LandArea  \\\n",
       "0  NaN             199    CONDO-BLDG    C-1     23-67    3499.0   \n",
       "1  NaN             199    CONDO-BLDG    C-1     77-81    1835.0   \n",
       "2  NaN             199    CONDO-BLDG      C     97-91    2900.0   \n",
       "3  NaN             199    CONDO-BLDG    C-1     23-67    3499.0   \n",
       "4   2A             102   CONDOMINIUM    NaN  23-29-2A       0.0   \n",
       "\n",
       "           ...           Systems_Plumbing Condition_YearBuilt  \\\n",
       "0          ...                        NaN                 0.0   \n",
       "1          ...                        NaN                 0.0   \n",
       "2          ...                        NaN                 0.0   \n",
       "3          ...                        NaN                 0.0   \n",
       "4          ...                        NaN              1873.0   \n",
       "\n",
       "  Condition_InteriorCondition Condition_OverallCondition  \\\n",
       "0                         NaN                        NaN   \n",
       "1                         NaN                        NaN   \n",
       "2                         NaN                        NaN   \n",
       "3                         NaN                        NaN   \n",
       "4                         NaN                    Average   \n",
       "\n",
       "  Condition_OverallGrade Parking_Open Parking_Covered Parking_Garage  \\\n",
       "0                    NaN          0.0             0.0            NaN   \n",
       "1                    NaN          0.0             0.0            NaN   \n",
       "2                    NaN          0.0             0.0            NaN   \n",
       "3                    NaN          0.0             0.0            NaN   \n",
       "4                Average          0.0             0.0            0.0   \n",
       "\n",
       "  UnfinishedBasementGross FinishedBasementGross  \n",
       "0                   574.0                   0.0  \n",
       "1                  1430.0                   0.0  \n",
       "2                   800.0                   0.0  \n",
       "3                  1308.0                   0.0  \n",
       "4                     0.0                   0.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and peek at your data. Change the file name as needed. \n",
    "raw_data_df = pd.read_csv('Cambridge.csv', parse_dates=[0]) \n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yes' 'No']\n",
      "['Yes' 'No']\n",
      "['2017-01-01T00:00:00.000000000' '2016-01-01T00:00:00.000000000'\n",
      " '2015-01-01T00:00:00.000000000' '2014-01-01T00:00:00.000000000'\n",
      " '2013-01-01T00:00:00.000000000' '2012-01-01T00:00:00.000000000'\n",
      " '2011-01-01T00:00:00.000000000' '2010-01-01T00:00:00.000000000'\n",
      " '2009-01-01T00:00:00.000000000' '2008-01-01T00:00:00.000000000'\n",
      " '2007-01-01T00:00:00.000000000' '2006-01-01T00:00:00.000000000'\n",
      " '2005-01-01T00:00:00.000000000' '2004-01-01T00:00:00.000000000'\n",
      " '2003-01-01T00:00:00.000000000' '2002-01-01T00:00:00.000000000'\n",
      " '2001-01-01T00:00:00.000000000' '2000-01-01T00:00:00.000000000'\n",
      " '1999-01-01T00:00:00.000000000' '1998-01-01T00:00:00.000000000'\n",
      " '1997-01-01T00:00:00.000000000' '1996-01-01T00:00:00.000000000'\n",
      " '1995-01-01T00:00:00.000000000' '1994-01-01T00:00:00.000000000'\n",
      " '1993-01-01T00:00:00.000000000']\n",
      "[81 31 61 39 71 26 62 38 72 24 40 75 23 44 79 29 69 27 45 80 30 82 68 34 84\n",
      " 73 42 43 77 22 32 76 67 36 37 46 49 78 33 47]\n"
     ]
    }
   ],
   "source": [
    "# You can explore unique entires by stating the column and using .unique() like this:\n",
    "print(raw_data_df[\"Took in July\"].unique())\n",
    "print(raw_data_df[\"First time taking\"].unique())\n",
    "print(raw_data_df[\"Year\"].unique())\n",
    "print(raw_data_df[\"Passing Rate (%)\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Took in July</th>\n",
       "      <th>First time taking</th>\n",
       "      <th>Passing Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year Took in July First time taking  Passing Rate (%)\n",
       "0 2017-01-01          Yes               Yes                81\n",
       "1 2017-01-01          Yes                No                31\n",
       "4 2016-01-01          Yes               Yes                71\n",
       "5 2016-01-01          Yes                No                26\n",
       "8 2015-01-01          Yes               Yes                72"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can explore rows with a specific value like so\n",
    "raw_data_df[raw_data_df[\"Took in July\"]=='Yes'].head() # remove .head() to see all entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 100 \n",
      "Size of entires matching filter: 50 \n"
     ]
    }
   ],
   "source": [
    "# You can count the number of rows like so\n",
    "print(\"Size of entire table: %s \"%len(raw_data_df))\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Took in July\"]=='Yes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entires matching filter: 50 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Took in July</th>\n",
       "      <th>First time taking</th>\n",
       "      <th>Passing Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year Took in July First time taking  Passing Rate (%)\n",
       "2  2017-01-01           No               Yes                61\n",
       "3  2017-01-01           No                No                39\n",
       "6  2016-01-01           No               Yes                62\n",
       "7  2016-01-01           No                No                38\n",
       "10 2015-01-01           No               Yes                62"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can invert a match by using the 'not equal' evaluation.\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Took in July\"]!='Yes']))\n",
    "raw_data_df[raw_data_df[\"Took in July\"]!='Yes'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 25 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Took in July</th>\n",
       "      <th>First time taking</th>\n",
       "      <th>Passing Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year Took in July First time taking  Passing Rate (%)\n",
       "3  2017-01-01           No                No                39\n",
       "7  2016-01-01           No                No                38\n",
       "11 2015-01-01           No                No                40\n",
       "15 2014-01-01           No                No                44\n",
       "19 2013-01-01           No                No                44"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make a new table from your filtered rows like so\n",
    "processed_data_df = raw_data_df[raw_data_df[\"Took in July\"]!='Yes']\n",
    "processed_data_df = processed_data_df[processed_data_df[\"First time taking\"]!='Yes']\n",
    "# Note how I filtered first on raw_data_df and then on processed_data_df\n",
    "\n",
    "\n",
    "# So how many entires are there?\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df))\n",
    "# Let's peak at the table.\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 25 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Took in July</th>\n",
       "      <th>First time taking</th>\n",
       "      <th>Passing Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year Took in July First time taking  Passing Rate (%)\n",
       "3  2017-01-01           No                No                39\n",
       "7  2016-01-01           No                No                38\n",
       "11 2015-01-01           No                No                40\n",
       "15 2014-01-01           No                No                44\n",
       "19 2013-01-01           No                No                44"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the special case of when a calue is NaN, you can filter based on the value not being null (i.e., empty)\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"Took in July\"])]\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"First time taking\"])]\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df)) # in the example data, this gets rid of a few rows\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['Year'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-e861220771f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can remove unwanted colums like so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# for a single column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocessed_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# for multiple columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m processed_data_df = processed_data_df.drop([\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Year'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# You can remove unwanted colums like so\n",
    "# for a single column\n",
    "processed_data_df = processed_data_df.drop('Year', 1)\n",
    "# for multiple columns\n",
    "processed_data_df = processed_data_df.drop([\n",
    "                                            'How.satisfied.are.you.with.Somerville.as.a.place.to.live.',\n",
    "                                            'How.satisfied.are.you.with.your.neighborhood.'\n",
    "                                           ], 1)\n",
    "\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['How.happy.do.you.feel.right.now.'\\n 'How.satisfied.are.you.with.your.life.in.general.'\\n 'What.is.your.annual.household.income.' 'Age.'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e088cbc66f53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                         \u001b[0;34m'How.satisfied.are.you.with.your.life.in.general.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                         \u001b[0;34m'What.is.your.annual.household.income.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                         \u001b[0;34m'Age.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                      ]].copy()\n\u001b[1;32m      8\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['How.happy.do.you.feel.right.now.'\\n 'How.satisfied.are.you.with.your.life.in.general.'\\n 'What.is.your.annual.household.income.' 'Age.'] not in index\""
     ]
    }
   ],
   "source": [
    "# Alternativly, if you want to make a new table from a subset of columns, you can do so like this.\n",
    "processed_data_df = processed_data_df[[\n",
    "                                        'How.happy.do.you.feel.right.now.', \n",
    "                                        'How.satisfied.are.you.with.your.life.in.general.', \n",
    "                                        'What.is.your.annual.household.income.',\n",
    "                                        'Age.'\n",
    "                                     ]].copy()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can rename columns like so.\n",
    "processed_data_df = processed_data_df.rename(columns={\n",
    "                                                        'How.happy.do.you.feel.right.now.': 'happy', \n",
    "                                                        'How.satisfied.are.you.with.your.life.in.general.': 'satisfied',\n",
    "                                                        'What.is.your.annual.household.income.': 'income',\n",
    "                                                        'Age.': 'age',\n",
    "                                                     })\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can replace values in a column based on logic like so\n",
    "# Note: I used the unique values found above to inform my logic.\n",
    "# That is, I took the unique text lables and translated them into numbers.\n",
    "# It's clear that different surveys had different buckets. So I probably \n",
    "# sould limit myself to years using the same metrics, but for our purposes\n",
    "# I'm just going to run with a quick and dirty translation. \n",
    "\n",
    "processed_data_df.loc[processed_data_df['income'] == 'Less than $10,000', 'income'] = 5000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '10,000 - $19,999', 'income'] = 15000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$10,000 to $24,999', 'income'] = 17500\n",
    "processed_data_df.loc[processed_data_df['income'] == '20,000 - $29,999', 'income'] = 25000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$25,000 to $49,999', 'income'] = 37500\n",
    "processed_data_df.loc[processed_data_df['income'] == '30,000 - $39,999', 'income'] = 35000\n",
    "processed_data_df.loc[processed_data_df['income'] == '40,000 - $49,999', 'income'] = 45000\n",
    "processed_data_df.loc[processed_data_df['income'] == '50,000 - $59,999', 'income'] = 55000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$50,000 to $74,999', 'income'] = 62500\n",
    "processed_data_df.loc[processed_data_df['income'] == '60,000 - $69,999', 'income'] = 65000\n",
    "processed_data_df.loc[processed_data_df['income'] == '70,000 - $79,999', 'income'] = 75000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$75,000 to $99,999', 'income'] = 87500\n",
    "processed_data_df.loc[processed_data_df['income'] == '80,000 - $89,999', 'income'] = 85000\n",
    "processed_data_df.loc[processed_data_df['income'] == '90,000 - $99,999', 'income'] = 95000\n",
    "processed_data_df.loc[processed_data_df['income'] == '100,000 and up', 'income'] = 100000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$100,000 to $149,999', 'income'] = 125000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '$150,000 or more', 'income'] = 150000\n",
    "\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-21', 'age'] = 24\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-24', 'age'] = 21\n",
    "processed_data_df.loc[processed_data_df['age'] == '22-25', 'age'] = 23.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '25-34', 'age'] = 29.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '26-30', 'age'] = 28\n",
    "processed_data_df.loc[processed_data_df['age'] == '31-40', 'age'] = 35.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '35-44', 'age'] = 39.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '41-50', 'age'] = 46.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '45-54', 'age'] = 48\n",
    "processed_data_df.loc[processed_data_df['age'] == '51-60', 'age'] = 55.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '55-64', 'age'] = 58\n",
    "processed_data_df.loc[processed_data_df['age'] == '61+', 'age'] = 61\n",
    "processed_data_df.loc[processed_data_df['age'] == '65-74', 'age'] = 69.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '75 or older', 'age'] = 75\n",
    "processed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\n",
    "processed_data_df = processed_data_df.apply(pd.to_numeric, errors='coerce')\n",
    "# errors='coerce' will set things that can't be converted to numbers to NaN\n",
    "# so you'll want to drop these like so.\n",
    "processed_data_df = processed_data_df.dropna()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can add a columns like so.\n",
    "processed_data_df[\"happy_Y_N\"] = \"N\"\n",
    "processed_data_df[\"satisfied_Y_N\"] = \"N\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then you can customize these new coulmns using the same method as above. \n",
    "processed_data_df.loc[processed_data_df['happy'] >= 5, 'happy_Y_N'] = \"Y\"\n",
    "processed_data_df.loc[processed_data_df['satisfied'] >= 5, 'satisfied_Y_N'] = \"Y\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm now going to make a set of tables to be used in training some models\n",
    "# The first set will be for linear regressions where the traget is numeric.\n",
    "# Happiness\n",
    "happy_lin_df = processed_data_df[[\n",
    "                               'happy', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_lin_df = processed_data_df[[\n",
    "                               'satisfied', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second set will be for classifiers where the target is a class.\n",
    "# Happiness\n",
    "happy_class_df = processed_data_df[[\n",
    "                               'happy_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_class_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_class_df = processed_data_df[[\n",
    "                               'satisfied_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taining and Validation\n",
    "\n",
    "Above I created four datasets worth exploring: \n",
    "- **`happy_lin_df`**. The data needed to access *happiness* along a continuous variable.\n",
    "- **`sat_lin_df`**. The data needed to access *satisfaction* along a continuous variable.\n",
    "- **`happy_class_df`**. The data needed to access *happiness* as a categorical variable.\n",
    "- **`sat_class_df`**. The data needed to access *satisfaction* as a categorical variable.\n",
    "\n",
    "Let's take them each in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_lin_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_lin_df\n",
    "\n",
    "data = data[data[\"happy\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"happy ~ age + income\", training).fit()\n",
    "#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "features_train = training.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_lin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_lin_df\n",
    "\n",
    "data = data[data[\"satisfied\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"satisfied ~ age + income\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "\n",
    "features_train = training.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"happy_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"satisfied_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
